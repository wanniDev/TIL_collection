# 카프카 브로커

카프카 브로커는 카프카 클러스터에서 메시지를 저장하고 전송하는 서버를 의미합니다. 프로듀서가 보낸 메시지를 수신하여 토픽으로 구분하고, 컨슈머는 토픽으로 구분된 메시지를 읽습니다. 여기서 잊지말아야 할 것은 컨슈머는 브로커가 수신한 메시지를 *읽는 것이지, 가져가는 것이 아닙니다.* 따라서, 컨슈머가 메시지를 읽을 때마다 브로커가 저장한 메시지가 삭제되는 것은 아닙니다.

## 브로커의 역할

### 1. 컨슈머 오프셋 저장

컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋합니다. 커밋한 오프셋은 `__consumer_offsets` 토픽에 저장됩니다. 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리합니다.

### 2. 그룹 코디네이터

코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 합니다. 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 데이터가 처리되도록 도와줍니다. 이렇게 파티션을 재할당하는 과정을 `rebalance`라고 부릅니다.

### 3. 데이터의 저장

- 카프카를 실행할 때 `config/server.properties`의 `log.dir`옵션에 정의한 데릭토리에 데이터를 저장합니다. 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장합니다.
- `hello.kafka` 토픽의 0번 파티션에 존재하는 데이터를 확인할 수 있습니다. log 에는 메시지와 메타데이터를 저장합니다. `index`는 메시지의 오프셋을 인덱싱한 정보를 담은 파일입니다. `timeindex` 파일에는 메시지에 포함된 `timestamp` 값을 기준으로 인덱싱한 정보가 담겨있습니다.

```shell
$ ls /tmp/kafka-logs
__consumer_offsets-0	__consumer_offsets-21
...
$ ls /tmp/kafka-logs/hello.kafka-0
00000...000000.index	0000...000.log
00000...000000.timeindex	leader-epoch-checkpoint
```

## 로그와 세그먼트

**레코드**는 메시지를 나타내는 단위이다. 레코드는 Topic 내에서 생성되고, Producer가 보내며, Consumer가 가져와서 처리한다.

카프카 레코드는 다음과 같은 구성 요소로 이루어져 있다.

1. **Key** : 레코드의 고유 식별자이다. Key는 선택 사항이며, 메시지를 유일하게 식별하는 데 사용된다.
2. **Value** : 레코드에 저장된 실제 데이터이다. Value는 일반적으로 바이트 배열 형태로 저장되며, 메시지를 보내는 클라이언트에서 직접 정의된다.
3. **offset** : 레코드에 기록된 메시지의 위치. 레코드가 브로커에 저장될 때만 offset이 지정되어 저장된다. 각 메시지는 파티션별로 고유한 오프셋을 가지므로 컨슈머에서 중복 처리를 방지하기 위한 목적으로도 사용됨. 
4. **Timestamp** : 레코드가 생성된 시간이다. 스트림 프로세싱에서 활용하기 위한 시간을 저장하는 용도로 사용된다. Timestamp는 Producer가 레코드를 생성한 시간을 기록하며, Consumer는 메시지를 가져올 때 Timestamp를 사용하여 메시지의 순서를 결정할 수 있다.
5. **Headers** : 레코드에 포함될 수 있는 추가적인 메타데이터이다. Headers는 Key, Value, Timestamp와 함께 레코드의 일부로 저장될 수 있으며, Producer와 Consumer 간의 상호 작용에 사용된다. 레코드의 스키마 버전이나 포맷과 같이 데이터 프로세싱에 참고할만한 정보를 담아서 사용할 수 있다.

카프카 레코드는 대용량 데이터 처리와 분산 저장을 위한 중요한 구성 요소이다. 레코드는 메시지의 식별, 저장, 처리 및 검색을 가능하게 한다. 또한, 레코드는 일련의 메시지를 유일하게 식별하여 순서를 보장하고, 메시지에 추가적인 메타데이터를 포함할 수 있도록 한다.

컨슈머가 프로듀서가 만든 레코드를 가져가도 브로커 안의 오프셋 데이터는 삭제되지 않고 파일시스템을 통해 .log의 형태로 저장된다.

```shell
$ ls /tmp/kafka-logs/hello.kafka-0
0000...000.log
0000...010.log
0000...020.log
```

- **log.segment.bytes :** 바이트 단위의 최대 세그먼트 크기 지정. 기본 값은 1GB.
- **log.roll.ms(hours) :** 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기. 기본 값은 7일.

## 액티브 세그먼트

가장 마지막 세그먼트 파일(쓰기가 일어나고 있는 파일)을 액티브 세그먼트라고 부른다. 액티브 세그먼트는 브로커의 삭제 대상에서 포함되지 않는다. 액티브 세그먼트가 아닌 세그먼트는 retention 옵션에 따라 삭제 대상으로 지정된다.

### 세그먼트와 삭제 주기(cleanup.policy=delete)

- **retention.ms(minutes, hours) : **세그먼트를 보유할 최대 기간으로. 기본은 7일.
  - 보통 3일로 정함. 그러면 금요일 이후 다음 주 월요일에 로그가 세그먼트가 삭제되기 때문에 금요일 밤에 장애가 나도 월요일에 초기화된 상태로 매끄럽게 대응이 가능함.
- **retention.bytes : **파티션당 로그 적재 바이트 값. 기본 값은 -1(지정하지 않음)
- **log.retention.check.interval.ms :** 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격. 기본 값은 5분.

**카프카에서 데이터는 세그먼트 단위로 삭제가 발생하기 때문에 로그 단위(레코드 단위)로 개별 삭제는 불가능함.** 또한, 로그(레코드)의 메시지 키, 메시지 값, 오프셋, 헤더 등 이미 적재된 데이터에 대해서 수정 또한 불가능하기 때문에 데이터를 적재할 때(프로듀서) 또는 데이터를 사용할 때(컨슈머) 데이터를 검증하는 것이 좋음.

### 세그먼트와 삭제 주기(cleanup.policy=compact)

토픽 압축 정잭은 일반적으로 생각하는 zip과 같은 압축과는 다른 개념. 여기서 압축이란 메시지 키 별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책을 뜻한다. 그렇기 때문에 삭제(delete) 정책과 다르게 일부 레코드만 삭제가 될 수 있다. 압축은 액티브 세그먼트를 제외한 데이터가 대상임.

### 테일/헤드 영역, 클린/더티 로그

- **테일 영역 : **압축 정책에 의해 압축이 완료된 레코드를 클린(clean) 로그 라고도 부릅니다. 중복 메시지 키가 없습니다.
- **헤드 영역 : **압축 정책이 되기 전 레코드들. 더티(dirty) 로그 라고도 부릅니다. 중복된 메시지 키가 있습니다.

데이터의 압축 시작 시점은 `min.cleanable.dirty.ratio` 옵션값을 따릅니다.

`min.cleanable.dirty.ratio` 옵션 값은 액티브 세그먼트를 제외한 세그먼트에 남아 있는 테일 영역의 레코드 개수와 헤드 영역의 레코드 개수의 비율을 뜻한다.

만약에 해당 옵션을 0.5로 설정한다면 테일 영역의 레코드 개수가 헤드 영역의 레코드 개수와 동일할 경우 압축이 실행된다. 0.9와 같이 크게 설정하면 한번 압축을 할 때 많은 데이터가 줄어드므로 효과가 좋다. 하지만 0.9까지 용량을 차지하기 때문에 용량 효율이 좋지 않다.

반면에 0.1과 같이 작게 설정하면 압축이 자주 일어나서 가장 최신 데이터만 유지할 수 있지만 압축이 자주 발생하여 브로커에 부담을 줄 수 있다.

## 카프카 브로커의 역할 정리

- 카프카의 브로커는 말 그대로 중개자(broker) 역할을 하고 있습니다.
- 프로듀서가 송신한 메시지를 수신하여, 로그의 형태로 저장하고 사전에 설정한 정책에 따라 저장한 로그파일들을 관리합니다.
- 컨슈머가 메시지를 가져간다고, 로그 파일이 지워지는 것이 아니며, 저장된 로그 파일은 사전에 설정한 정책에 따라 세그먼트 단위로 삭제됩니다.
- 브로커에서 관리하는 로그가 쌓이면 시스템에 영향을 줄 수 있으니, 카프카에서 제공하는 관리 정책을 잘 파악하고 상황에 맞게 구성하는 것이 중요합니다.

