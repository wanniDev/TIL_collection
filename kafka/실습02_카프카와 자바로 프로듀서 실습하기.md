# 카프카와 자바로 프로듀서 실습하기

카프카 주키퍼와 브로커를 로컬에 띄워보고, 브로커에게 메시지를 생성하고 생성내역을 확인하는 부분을 실습해서, 카프카가 어떻게 동작하는지 어느정도 감을 잡아보도록 하겠습니다.

이 실습은 스프링을 사용하지 않고 오직 자바와 카프카 클라이언트 라이브러리만을 활용하였습니다.

## 준비물

- java 최소 1.8 이상
- Kafka-clients 2.5.0
- slf4j-simple

## Launching kafka server

소스 코드를 작성하고 실행해보기 전에 먼저 카프카 서버를 동작시켜야 합니다. 살짝 리마인드 하자면, 카프카 2 버전대는 카프카 클러스터(브로커 묶음)를 실행하기 위해선 주키퍼를 먼저 동작시켜야 합니다. 콘솔을 활용하자면, 아래와 같은 명령어를 실행하면 됩니다.

그러나, 콘솔을 실행하기 전에 터미널이 카프카를 다운로드 받은 디렉토리로 이동이 되어있는 상탠지 확인을 해보시길 바랍니다.

**1. 주키퍼 실행하기**

```shell
$ bin/zookeeper-server-start.sh config/zookeeper.properties
```

**2. 카프카 브로커 실행하기**

```shell
$ bin/kafka-server-start.sh config/server.properties
```

## project setting

> 이 실습은 인텔리제이를 기준으로 진행했습니다.

- 인텔리J를 실행 후 java, gradle 프로젝트 생성

### build.gradle

```groovy
plugins {
    id 'java'
}

group 'com.example'
version '1.0'

sourceCompatibility = 1.8
targetCompatibility = 1.8

repositories {
    mavenCentral()
}

dependencies {
    implementation 'org.apache.kafka:kafka-clients:2.5.0'
    implementation  'org.slf4j:slf4j-simple:1.7.30'
}
```

## simple producer

단순히 브로커에 메시지를 생성하는 코드입니다. 따로 컨슈머 애플리케이션은 구현하지 않았기 때문에, 생성한 메세지는 콘솔 명령어로 '소비' 하겠습니다.

```java
package com.example;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;

public class SimpleProducer {
    private final static Logger logger = LoggerFactory.getLogger(SimpleProducer.class);
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "localhost:9092"; // hosts 파일을 확인하고 환경에 맞게 바꿔주세요.

    public static void main(String[] args) {

        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

        String messageValue = "testMessage";
        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
        producer.send(record);
        logger.info("{}", record);
        producer.flush();
        producer.close();
    }
}
```

위의 코드를 해설하자면, localhost:9092 서버 호스트를 활용하여, 프로듀서가 브로커에게 토픽이 test인 메시지 "testMessage"를 보내는 코드입니다. 따로 작성해놓은 컨슈머 애플리케이션 코드는 없으니 아래와 같은 명령어로  메시지가 소비되는 것을 모니터링 하도록 하겠습니다.

```shell
$ bin/kafka-console-consumer.sh \
--bootstrap-server my-kafka:9092 \  
--topic test --from-beginning

```

만약 프로듀서 애플리케이션이 제대로 동작했다면, 위에서 명령어를 입력한 터미널에서 컨슈머가 소비한 메시지를 출력할 것입니다.

## key-value producer

프로듀서는 내부에서 레코드를 구성해서 파티셔너로 파티션을 지정해서 클러스터에 전송을 합니다. 레코드에는 여러가지 헤더가 있지만, 그 중에서 가장 많이 쓰이는 헤더로는 '메시지 키'와 '메시지 값'이 있습니다.

메시지 값만 지정해도 되지만, '메시지 키'를 활용하면 파티셔너가 'RoundRobinPartitioner'에서 'UniformStickyPartitioner'로 지정되어 활용 분야가 좀 더 넓어집니다.

```java
package com.example;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import java.util.Properties;

public class ProducerWithKeyValue {
    private final static String TOPIC_NAME = "test";
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

    public static void main(String[] args) {

        Properties configs = new Properties();
        configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
        configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

        ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "Pangyo", "Pangyo");
        producer.send(record);
        ProducerRecord<String, String> record2 = new ProducerRecord<>(TOPIC_NAME, "Busan", "Busan");
        producer.send(record2);
        producer.flush();
        producer.close();
    }
}
```
